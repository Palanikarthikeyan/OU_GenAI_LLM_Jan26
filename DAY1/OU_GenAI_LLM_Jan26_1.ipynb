{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296bd40-21b3-4b33-b311-ca218d5e3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "www.python.org -- download -- python - General python - There is no ML module  \n",
    "Vs\n",
    "https://www.anaconda.com/download -->python = General python + ML modules + DE modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63d2a18-48b6-4017-b04e-e157251a2267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206a5d7c-ff10-4210-b04a-12ba7a7f9c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(15)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe16ad0f-9078-40f2-b832-ec9bf086bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bcf2d-6cc8-4c5f-af27-17a2e3dd9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c14a784-b211-4209-bcdf-a6ab4880c561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: nltk\n",
      "Version: 3.9.1\n",
      "Summary: Natural Language Toolkit\n",
      "Home-page: https://www.nltk.org/\n",
      "Author: NLTK Team\n",
      "Author-email: nltk.team@gmail.com\n",
      "License: Apache License, Version 2.0\n",
      "Location: C:\\ProgramData\\anaconda3\\Lib\\site-packages\n",
      "Requires: click, joblib, regex, tqdm\n",
      "Required-by: llama-index, llama-index-core, unstructured\n"
     ]
    }
   ],
   "source": [
    "! pip show nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8ae8db-7a05-4f4b-8890-676c309e8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"i likes to read machine learning algorithm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371740bc-d5b0-4f0f-b79a-191967afeeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74250b03-e6bd-4b60-90ba-08c9c8c50f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "LookupError\n",
    ">>> import nltk\n",
    ">>> nltk.download('punkt_tab') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac85ac4-6bc9-483d-b5c6-4a0388f528b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'likes', 'to', 'read', 'machine', 'learning', 'algorithm']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff66e8e-9c92-4bd0-84bd-0b140fd9908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a4f28b-0f40-4bd5-8ca8-31260a8b14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c67e932-3257-497f-8ce2-848f15772ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '''hello welcome,to gen ai training\n",
    "do activity ! to become nlt learning\n",
    "all the gen ai llm models are built on\n",
    "top of nlp'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a46b89-e022-4bde-87a8-f92b2edf2596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'gen',\n",
       " 'ai',\n",
       " 'training',\n",
       " 'do',\n",
       " 'activity',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'nlt',\n",
       " 'learning',\n",
       " 'all',\n",
       " 'the',\n",
       " 'gen',\n",
       " 'ai',\n",
       " 'llm',\n",
       " 'models',\n",
       " 'are',\n",
       " 'built',\n",
       " 'on',\n",
       " 'top',\n",
       " 'of',\n",
       " 'nlp']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebbac0a1-8a55-4c79-bcd9-8f6eecc9b91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello welcome,to gen ai training\\ndo activity !',\n",
       " 'to become nlt learning\\nall the gen ai llm models are built on\\ntop of nlp']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12aa700-6bdd-4cac-b54f-ae7f6abda5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'do',\n",
       " 'this',\n",
       " ',',\n",
       " 'can',\n",
       " 'i',\n",
       " '?',\n",
       " 'ab',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'def',\n",
       " \"'\",\n",
       " 'g',\n",
       " 'hi',\n",
       " ':',\n",
       " 'j']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = \"i can't do this, can i? ab'c def'g hi:j\"\n",
    "word_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5772e99-785e-4385-ab8d-ed100321dfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'can',\n",
       " \"'\",\n",
       " 't',\n",
       " 'do',\n",
       " 'this',\n",
       " ',',\n",
       " 'can',\n",
       " 'i',\n",
       " '?',\n",
       " 'ab',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'def',\n",
       " \"'\",\n",
       " 'g',\n",
       " 'hi',\n",
       " ':',\n",
       " 'j']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68397aaa-ea42-4b48-833d-824f7433821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learn'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming - reduce root word --- ex: learning  --- learn \n",
    "#           ================= // stem \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "obj_stem = PorterStemmer()\n",
    "obj_stem.stem(\"learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82579cc-8ec8-4609-9c89-c6a2b2432587",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk/ <== package \n",
    "  -- tokenize.py <== module\n",
    "        |->def word_tokenize()\n",
    "        |->def wordpunct_tokenize()\n",
    "  -- stem.py <== module\n",
    "        |->class PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425e97b9-af52-4b01-95cc-8dd20ad29e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_stem.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39ed30d2-38d2-4e1c-979c-6df43161ed11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_stem.stem(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f34b976-1157-4caa-88f2-77e31fc3beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "# RegexpStemmer('Regxpattern') ->obj\n",
    "\n",
    "reg_stem = RegexpStemmer(\"sh$|s$|e$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c3dca4c-dba8-43d6-9175-00141162f2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00ec9713-e3c3-4f85-9a1d-2a9f24d2e5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ba'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem(\"bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25e838f4-51b0-4e80-b43a-520a89638ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratulation'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a914e0bc-fd4f-4eb0-a9df-b66b19c372bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization - lemma\n",
    "# reducing root word - based on pos = v,av,..\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatize_obj = WordNetLemmatizer()\n",
    "lemmatize_obj.lemmatize(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e20a6e99-a0ba-4a7b-88b7-03eea84e77d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_obj.lemmatize(\"eating\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77549cb2-196f-4877-8e50-c8fd1e538ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_obj.lemmatize(\"history\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcea476-b5dd-4a79-986a-3c7e4d052ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization\n",
    "|\n",
    "stem/lemma \n",
    "|\n",
    "the hotel food is good  --> vector size is 5 \n",
    "|\n",
    "apply stop words \n",
    "|\n",
    "// hotel food good -->vector size is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853879c-1a05-4cee-bbda-87f470168876",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopword -- NLP preprocessing\n",
    "========\n",
    "    |->not carring significant meaning \n",
    "Reduce noise\n",
    "-------------//reduce vector size - improve the processing efficiency\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2381d7de-56f5-486b-92ca-1d25c905681c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "#stopwords.words('french')\n",
    "#stopwords.words('arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f532d-b9a5-4cc7-8275-7b1ddb3ff2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenization ->token - reduce this token ->stemm ->lemma ->stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87abffa-b875-46e9-8083-d3c5bd23594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Given_list = [\"words\",\"eats\",\"eatern\",\"writing\",\n",
    "              \"writes\",\"programming\",\"program\",\n",
    "              \"history\",\"finally\",\"finalized\"]\n",
    "\n",
    "# import nltk module\n",
    "#         |--> PorterStemmer - root words\n",
    "#         |--> WordNetLemmatizer - pos = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf918d05-ee7c-4856-b9d8-18f4c9156100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words    ---->word\n",
      "eats    ---->eat\n",
      "eatern    ---->eatern\n",
      "writing    ---->write\n",
      "writes    ---->write\n",
      "programming    ---->program\n",
      "program    ---->program\n",
      "history    ---->histori\n",
      "finally    ---->final\n",
      "finalized    ---->final\n"
     ]
    }
   ],
   "source": [
    "Given_list = [\"words\",\"eats\",\"eatern\",\"writing\",\n",
    "              \"writes\",\"programming\",\"program\",\n",
    "              \"history\",\"finally\",\"finalized\"]\n",
    "\n",
    "stemm_obj = PorterStemmer()\n",
    "\n",
    "for var in Given_list:\n",
    "    print(f'{var}    ---->{stemm_obj.stem(var)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7504a054-7073-4d97-8c6e-c2581d5de110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words ---->word\n",
      "eats ---->eat\n",
      "eatern ---->eatern\n",
      "writing ---->write\n",
      "writes ---->write\n",
      "programming ---->program\n",
      "program ---->program\n",
      "history ---->history\n",
      "finally ---->finally\n",
      "finalized ---->finalize\n"
     ]
    }
   ],
   "source": [
    "Given_list = [\"words\",\"eats\",\"eatern\",\"writing\",\n",
    "              \"writes\",\"programming\",\"program\",\n",
    "              \"history\",\"finally\",\"finalized\"]\n",
    "\n",
    "lemm_obj = WordNetLemmatizer()\n",
    "\n",
    "for var in Given_list:\n",
    "    print(f'{var} ---->{lemm_obj.lemmatize(var,pos='v')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0402853b-57f7-4898-b721-c4e4ad2b9d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'this is an example displying of list of or collection of stop words filters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a497ffd4-92d8-4456-8c9f-743ed107dfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'displying',\n",
       " 'of',\n",
       " 'list',\n",
       " 'of',\n",
       " 'or',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'filters']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b9dbc08-7d7d-4c67-8991-1d79e38b5d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example\n",
      "displying\n",
      "list\n",
      "collection\n",
      "stop\n",
      "words\n",
      "filters\n"
     ]
    }
   ],
   "source": [
    "for var in word_tokenize(msg):\n",
    "    if var not in stopwords.words('english'):\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b121bb2a-c4dc-4c95-8b91-a915d779d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n",
      "displying\n",
      "list\n",
      "collection\n",
      "STOP\n",
      "words\n",
      "filters\n"
     ]
    }
   ],
   "source": [
    "msg = 'This is an Example displying OF list of or collection of STOP words filters'\n",
    "for var in word_tokenize(msg):\n",
    "    if var.lower() not in stopwords.words('english'):\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fcb2331-5d2d-4c2e-92c7-95a32d50b2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stop'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='STOP'\n",
    "s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49655d53-de91-419d-a2b6-c1ed97bbb817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STOP'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a02a86f-a271-48b7-9072-8680933debb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'STOP'.lower() in ['stop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e448910-a190-4e9e-b5c2-d712f3da59e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([['food'],['good'],['bad']])\n",
    "\n",
    "encoder_obj = OneHotEncoder(sparse_output=False)\n",
    "encoded = encoder_obj.fit_transform(data)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45f09f8c-115c-4154-8fab-c2de01857dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\"likes\",\"read\",\"nlp\", \"applications\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88dfada0-7774-4857-a403-7620a7da91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41344592-d35c-499e-81bb-bfeaa7735441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c6559-2f06-48d9-bba5-166595321c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def f1():\n",
    "...     return 10\n",
    "...\n",
    ">>> f1()\n",
    "10\n",
    ">>> def f2():\n",
    "...     yield 10\n",
    "...\n",
    ">>> f2()\n",
    "<generator object f2 at 0x0000020C4D9C9A80>\n",
    ">>>\n",
    ">>> next(f2())\n",
    "10\n",
    ">>> for var in f2():\n",
    "...     print(var)\n",
    "...\n",
    "10\n",
    ">>> list(f2())\n",
    "[10]\n",
    ">>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0a06b2a-dd6f-4134-8515-29c7aa675083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ngrams at 0x000001E3F4F05A40>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "d = [\"likes\",\"read\",\"nlp\", \"applications\",\"oracle\"]\n",
    "ngrams(d,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "952da5b2-8457-407c-8c74-0e30df6ab5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes',), ('read',), ('nlp',), ('applications',), ('oracle',)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(d,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ff6323b-ed6a-4bc4-94b0-93f22018ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes', 'read'),\n",
       " ('read', 'nlp'),\n",
       " ('nlp', 'applications'),\n",
       " ('applications', 'oracle')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(d,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5bd5ceb-90a2-4e9f-9095-b4c731d08c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes', 'read', 'nlp'),\n",
       " ('read', 'nlp', 'applications'),\n",
       " ('nlp', 'applications', 'oracle')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(d,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abe1f298-a9a3-4c60-abf7-077af7c08681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes', 'read', 'nlp', 'applications'),\n",
       " ('read', 'nlp', 'applications', 'oracle')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(d,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1990bcb-9346-45e5-a2b9-9b5f1e8c5c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes', 'read', 'nlp', 'applications', 'oracle')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(d,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4784ddf8-3c1c-4bc1-a65e-86b87ead295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(d,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f5b7841-be77-4550-994d-0b0eb458601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['bad', 'food', 'good'], dtype='<U4')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([['food'],['good'],['bad']])\n",
    "\n",
    "encoder_obj = OneHotEncoder(sparse_output=False)\n",
    "encoded = encoder_obj.fit_transform(data)\n",
    "print(encoder_obj.categories_)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a4599ae-e849-4b82-93dd-19466e4846db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cccb8f-84c5-411e-86fa-b6806ca62ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bag of words(BOW)\n",
    "===================\n",
    "|-> word -->vector[1,2,3]\n",
    "\n",
    "|-> word frequency \n",
    "|-> not word order/grammar\n",
    "\n",
    "Bag - contains list of item(token)\n",
    "====\n",
    "doc1: i likes nlp and i likes python\n",
    "doc2: python and nlp course\n",
    "\n",
    "[i,likes,nlp,and,python,course] <== doc1+doc2 - unique words\n",
    "\n",
    "n=6\n",
    "doc1 \n",
    "====\n",
    "word  - Count\n",
    "i    - 2\n",
    "likes - 2\n",
    "nlp - 1\n",
    "and - 1\n",
    "python - 1\n",
    "course - 0\n",
    "\n",
    "[2,2,1,1,1,0] - doc1 vector \n",
    "\n",
    "doc2\n",
    "----\n",
    "word - count\n",
    "i - 0\n",
    "likes - 0\n",
    "nlp - 1\n",
    "and - 1\n",
    "python - 1\n",
    "course - 1\n",
    "[0,0,1,1,1,1] -- doc2 vector \n",
    "\n",
    "|\n",
    "Word2Vector -- capture sematic meaning\n",
    "    hello -->[1.2,0.2,1,2]\n",
    "    hi --->[1.3,0.1,2,3]\n",
    "    banana --->[5,6.2,4.2] \n",
    "\n",
    "food - [food,dinner,dosa,.....]\n",
    "book - [book,notes,....]\n",
    "         =======================//\n",
    "\n",
    "I likes ......  <== predict the next word - NLP - Ngrams\n",
    "\n",
    "P(AI |likes ) = 0.6\n",
    "P(dosa|likes) = 0.3\n",
    "So --> AI <== 0.6 \n",
    "\n",
    "I likes AI\n",
    "---------------------\n",
    "Limited context \n",
    "Data sparsity \n",
    "Size of N\n",
    "-------------------\n",
    "N-gram model\n",
    "-------------\n",
    "count-based -- fixed window(n=1,2,3,4,5,6,..N)  Vs LLM - LargetContext(1000's of token)\n",
    "sparse vectors                                     |->Dense embeddings\n",
    "No Semantics                                       |->Semantic understanding\n",
    "\n",
    "vocs = 3 - food good bad                           |->Dense vector - 300dims \n",
    "see no'of 0s - not matching                         [0.12,0.23,-0.34,0.33]\n",
    "[[0., 1., 0.],\n",
    "[0., 0., 1.],                         \n",
    "[1., 0., 0.]])\n",
    "\n",
    "vocs = 50,000 words\n",
    "see no'of 0s \n",
    "Mostly zero = sparse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135a5bf-462e-4472-801b-269bea4fb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\karth>ollama --version\n",
    "ollama version is 0.14.3\n",
    "\n",
    "C:\\Users\\karth>ollama -v\n",
    "ollama version is 0.14.3\n",
    "\n",
    "C:\\Users\\karth>ollama list # list of loaded model in my local system\n",
    "NAME    ID    SIZE    MODIFIED\n",
    "\n",
    "C:\\Users\\karth>ollama pull nomic-embed-text:latest\n",
    "pulling manifest\n",
    "pulling 970aa74c0a90: 100% ▕██████████████████▏ 274 MB\n",
    "pulling c71d239df917: 100% ▕██████████████████▏  11 KB\n",
    "pulling ce4a164fc046: 100% ▕██████████████████▏   17 B\n",
    "pulling 31df23ea7daa: 100% ▕██████████████████▏  420 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "success\n",
    "\n",
    "C:\\Users\\karth>ollama pull gemma2:2b\n",
    "pulling manifest\n",
    "pulling 7462734796d6: 100% ▕██████████████████▏ 1.6 GB\n",
    "pulling e0a42594d802: 100% ▕██████████████████▏  358 B\n",
    "pulling 097a36493f71: 100% ▕██████████████████▏ 8.4 KB\n",
    "pulling 2490e7468436: 100% ▕██████████████████▏   65 B\n",
    "pulling e18ad7af7efb: 100% ▕██████████████████▏  487 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "success\n",
    "\n",
    "C:\\Users\\karth>ollama list\n",
    "NAME                       ID              SIZE      MODIFIED\n",
    "gemma2:2b                  8ccf136fdd52    1.6 GB    About a minute ago\n",
    "nomic-embed-text:latest    0a109f422b47    274 MB    3 minutes ago\n",
    "\n",
    "C:\\Users\\karth>\n",
    "\n",
    "C:\\Users\\karth>ollama run nomic-embed-text:latest\n",
    "Error: embedding models require input text. Usage: ollama run nomic-embed-text:latest \"your text here\"\n",
    "\n",
    "C:\\Users\\karth>ollama run nomic-embed-text:latest hello\n",
    "[0.017860368,-0.005880318,-0.17529128,-0.013721276,0.03403859,0.044752814,0.012422824,-0.0025509228,\n",
    " -0.014760505,-0.03928757,-0.009200146,0.051717155,0.05771218,0.057226323,0.045014214,-0.05359758,\n",
    " 0.028783012,-0.047195476,-0.039058723,0.026992228,0.009364105,\n",
    " -0.06674605,0.004949517,-0.0058987713,0.17222914,-0.004382981..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f8e29-8e0f-4113-935e-46fd2d2b56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commandline \n",
    "pip install -r requirements.txt\n",
    "\n",
    "in JupyterCell\n",
    "! pip install -r requirements.txt\n",
    "\n",
    "Refer:\n",
    "https://github.com/Palanikarthikeyan/OU_GenAI_LLM_Jan26/blob/main/DAY1/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f7dd528-ee85-4f34-8b91-d513f7ecef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0219f443-10f8-405a-9e57-e93887577f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_ollama.llms.OllamaLLM'>\n"
     ]
    }
   ],
   "source": [
    "print(OllamaLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481a0a3-f471-400d-828c-f805d8be42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_ollama/\n",
    "            |___llms.py\n",
    "                   |-------->class OllamaLLM:\n",
    "                                    ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4246c53-4d1b-4d5f-83d1-3e5ca57ee34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_obj = OllamaLLM(model='model_name')\n",
    "\n",
    "llm_obj.invoke('User Query?') -> result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6eb256-74b6-4c43-8661-3b4541299038",
   "metadata": {},
   "outputs": [],
   "source": [
    "In Command Prompt\n",
    "==================\n",
    "set OLLAMA_HOST=127.0.0.1:11435\n",
    "ollama serve \n",
    "|\n",
    "Listening on:127.0.0.1:11435\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "43823ad5-b1a6-400e-83b8-a4835f5b2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(OllamaLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d53a7a81-780c-4290-ad73-6bf8bbf857e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 2585\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm_obj = OllamaLLM(model='gemma2:2b')\n",
    "result = llm_obj.invoke('what is genAI?')\n",
    "print(type(result),len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3c33ae5-43f4-4a18-8087-3169117ce1bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Generative AI** is a subfield of artificial intelligence (AI) that focuses on creating new content, including text, images, audio, video, and code, based on learned patterns from existing data. \n",
      "\n",
      "Here's a breakdown:\n",
      "\n",
      "**Key Characteristics:**\n",
      "\n",
      "* **Creativity & Generation:**  Unlike traditional AI systems that focus on analysis or prediction, generative AI can produce original outputs like writing stories, generating artwork, composing music, or even designing software programs.\n",
      "* **Data-Driven Learning:**  Generative AI models are trained on massive datasets of existing content (text, images, code, etc.). This allows them to learn the underlying patterns and structures within that data.\n",
      "* **Automation & Efficiency:** By automating the creation process, generative AI can save time and effort for human creators, allowing them to focus on higher-level tasks like concept development and fine-tuning.\n",
      "\n",
      "**Types of Generative AI Models:**\n",
      "\n",
      "* **Text Generation:** GPT-3, LaMDA (Language Model for Dialogue Applications), BERT\n",
      "* **Image Generation:** DALL-E 2, Stable Diffusion, Midjourney\n",
      "* **Audio Generation:** Jukebox (music composition)\n",
      "* **Video & Code Generation:**  Growing rapidly with advancements in AI research.\n",
      "\n",
      "**Applications of Generative AI:**\n",
      "\n",
      "The possibilities for generative AI are vast and continue to grow:\n",
      "\n",
      "* **Content Creation:** Writing articles, generating social media content, designing marketing materials, creating music and art\n",
      "* **Research and Development:** Simulating complex systems, accelerating scientific discovery, developing new medical treatments\n",
      "* **Education:** Personalized learning experiences, interactive simulations, automated grading \n",
      "* **Entertainment:**  Interactive storytelling games, AI-generated movie scripts\n",
      "* **Business:** Generating customer service chatbots, automating internal tasks\n",
      "\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "While incredibly powerful, generative AI raises ethical concerns:\n",
      "\n",
      "* **Bias and Fairness:** Training data can contain biases, leading to the creation of biased outputs. \n",
      "* **Misinformation & Fake Content:**  Generated content can be manipulated to create false or misleading information. \n",
      "* **Copyright and Ownership:** Questions surrounding ownership of creations generated by AI systems are still being debated.\n",
      "\n",
      "\n",
      "**The Future of Generative AI:**\n",
      "\n",
      "Generative AI is a rapidly developing field with enormous potential to revolutionize how we work, play, learn, and experience the world.  As the technology continues to advance, we can expect even more creative and innovative applications in the future. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77d9e9f3-7310-4158-9f3e-fc7cd6f93768",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```cpp\n",
      "#include <iostream>\n",
      "\n",
      "using namespace std;\n",
      "\n",
      "// Function to calculate factorial using recursion\n",
      "int factorial(int n) {\n",
      "    if (n == 0) { // Base case: Factorial of 0 is 1\n",
      "        return 1;\n",
      "    } else {\n",
      "        return n * factorial(n - 1); // Recursive step: Multiply n by the factorial of (n-1)\n",
      "    }\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    int num;\n",
      "\n",
      "    cout << \"Enter a non-negative integer: \";\n",
      "    cin >> num;\n",
      "\n",
      "    if (num < 0) { // Error handling for negative input\n",
      "        cout << \"Factorial is undefined for negative numbers.\" << endl;\n",
      "    } else {\n",
      "        cout << \"The factorial of \" << num << \" is \" << factorial(num) << endl;\n",
      "    }\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **Include header:** `#include <iostream>` for input/output operations.\n",
      "2. **Namespace:** `using namespace std;` to avoid writing `std::` repeatedly.\n",
      "3. **`factorial` Function:**\n",
      "   - Takes an integer `n` as input.\n",
      "   - Uses recursion:\n",
      "     - Base case: If `n` is 0, return 1 (factorial of 0 is 1).\n",
      "     - Recursive step: Otherwise, multiply `n` by the factorial of `n - 1`.\n",
      "4. **`main` Function:**\n",
      "   - Prompts the user to enter a non-negative integer.\n",
      "   - Reads the input into variable `num`.\n",
      "   - Handles negative input with an error message.\n",
      "   - If input is valid:\n",
      "     - Calls the `factorial` function to calculate the factorial.\n",
      "     - Prints the result using `cout`.\n",
      "\n",
      "**How the Recursion Works:**\n",
      "\n",
      "- For example, if you call `factorial(5)`, it does this:\n",
      "    1. `5 * factorial(4)` \n",
      "    2. `5 * (4 * factorial(3))` \n",
      "    3. `5 * (4 * (3 * factorial(2)))`\n",
      "    4. ... and so on, until it reaches the base case of `factorial(0)`, where it returns 1. The results then get multiplied back up through the recursive calls, giving you the final answer: 5! = 120.\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "- **Recursion:** A technique where a function calls itself to solve smaller subproblems of the same type.\n",
      "- **Base case:** The stopping condition for recursion (needed in factorial).\n",
      "- **Recursive step:** The part of the function that calls itself with a slightly modified input (e.g., subtracting 1).\n",
      "\n",
      "**Error Handling:**\n",
      "\n",
      "It's crucial to include error handling in your program, especially when dealing with user input:\n",
      "   - Check if the entered number is actually non-negative.\n",
      "   - If negative, provide an informative message.  \n",
      "\n",
      "\n",
      "\n",
      "Let me know if you want to explore different ways of calculating factorial (using iteration or a more optimized version). \n"
     ]
    }
   ],
   "source": [
    "result = llm_obj.invoke('How to write factorial program in C++')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9445649-210c-4799-8657-f29c28e1fbce",
   "metadata": {},
   "source": [
    "llm = OllamaLLM(model='lamma') \n",
    "llm.invoke(\"what is AI?\")\n",
    "ResponseError: model 'lamma' not found (status code: 404)\n",
    "|\n",
    "Check - commandline --> ollama list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940164c-5002-41d5-8355-312dcdde1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af98734-1b9e-42eb-9088-cb792ff2571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1984 --- Q: PM of india     ----|        |\n",
    "         A: .....            ---| modelA |   <== User Ask Query - Who is the PM of India?\n",
    " ...\n",
    "\n",
    "2026                <== User Ask Query - Who is the PM of India?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab811b25-c678-4f67-b145-3d5bcb599843",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load our dataset \n",
    "document loading - class - get the document - metdata - info about loaded data + actual data (page_content)\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "TextLoader('input_file.txt') ->loader_object\n",
    "\n",
    "loader_object.load() -> documents = metadata + page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0ba28a3-b2dd-409b-83ca-39d0094f05ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x1e3803c9e80>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "TextLoader('my_docs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8e9cccc-f952-472d-bb7b-28f065c9d85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'my_docs.txt'}, page_content=\"LangChain is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nDevelopment: Build your applications using LangChain's open-source components and third-party integrations. Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.\\nProductionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\\nDeployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.\\n\\nfactorial value 5! is 120\")]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = TextLoader('my_docs.txt')\n",
    "loader_obj.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d823309-854e-4150-a652-b81dc6d140a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_obj = TextLoader('my_docs.txt')\n",
    "Text_docs = loader_obj.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d6857d0-31aa-4383-9501-52581f8921a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader_obj = PyPDFLoader('attention.pdf')\n",
    "pdf_docs = loader_obj.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8b25dd3-8a43-484a-b224-c79b654cc628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'my_docs.txt'}, page_content=\"LangChain is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nDevelopment: Build your applications using LangChain's open-source components and third-party integrations. Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.\\nProductionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\\nDeployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.\\n\\nfactorial value 5! is 120\")]\n"
     ]
    }
   ],
   "source": [
    "print(Text_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1926a131-9b44-4508-916f-d2ee9d161117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(pdf_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f220c27-93b6-40f1-86e5-beab966b4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e672cbdf-dd12-4f47-903b-e407a7d94b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3690ce50-a32c-42c6-8fd4-b0c3cb5b65cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.google.com', 'title': 'Google', 'language': 'en-IN'}, page_content='GoogleSearch Images Maps Play YouTube News Gmail Drive More »Web History | Settings | Sign in\\xa0Advanced searchGoogle offered in:  हिन्दी বাংলা తెలుగు मराठी தமிழ் ગુજરાતી ಕನ್ನಡ മലയാളം ਪੰਜਾਬੀ AdvertisingBusiness SolutionsAbout GoogleGoogle.co.in© 2026 - Privacy - Terms')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WebBaseLoader(web_path='URL') ->web_loader_obj.load()\n",
    "web_loader = WebBaseLoader(web_path='https://www.google.com')\n",
    "web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d94caf-c7b0-4212-bad2-fc815e946ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "# WikipediaLoader(query='Question') ->loader_obj.load() ->data\n",
    "#\n",
    "# WikipediaLoader(query=Question,load_max_docs=<count>) ->loader_obj.load() -->data\n",
    "#"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9bbd8a0-da18-49d4-8da2-6cb923c9d124",
   "metadata": {},
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "loader_obj = WikipediaLoader(query=\"What is AgenticAI?\")\n",
    "result = loader_obj.load()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b6e7a-3217-4260-9192-e1c5f838f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import <Select_Loader_Name> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e308d0f-ae6e-4256-9d35-71a1760a21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################   End of Day1 Session #####################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
