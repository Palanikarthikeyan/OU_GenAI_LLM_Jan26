{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96a1a3f-424f-4ee2-ab74-6ec6f4984629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6dd44c8-bf47-40a4-ae91-1e5116dd2337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.27\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\karth\\AppData\\Roaming\\Python\\Python313\\site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: langchain-community\n"
     ]
    }
   ],
   "source": [
    "! pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cd542-3f81-457c-b6bb-82e9de204ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoading -->Chunks -->Embedding -->StorestoVectorDB  <--------- Retrieval\n",
    "                                            |->similarity_search\n",
    "\n",
    "\n",
    "RetrievalQA\n",
    " |-->Chain - pipeline ( process1 | process2 ) \n",
    "                            |_________|    \n",
    "\n",
    "Retrival_object \n",
    "llm_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c2aac1-914d-4b7a-8969-82a35f56f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA # Higher version of langchain -> from langchain_classic.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f91824-528d-434f-ba0f-649dd4e1a4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 467, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "# step-1\n",
    "loader = TextLoader(\"my_docs.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# step-2\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200,chunk_overlap=20)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# step-3\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d7bf4e-eaa3-4814-93f5-858c02b6871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# step -4\n",
    "vectorstore = FAISS.from_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3748c92d-e407-4ff9-b6e7-537b32872203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18eea66-1886-4a00-ab8f-8998e8d7dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-5\n",
    "#vectorstore.similarity_search(\"what is langchain?\")\n",
    "retriever_obj = vectorstore.as_retriever() # Convert vector stores into a retriever object\n",
    "\n",
    "# Step-6 - create llm object\n",
    "llm_obj = ChatGroq(model=\"llama-3.1-8b-instant\",api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a6ad76-cdbf-4184-a146-0eb248b52bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-7 - Build Retrieval QA Chain \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm_obj,retriever=retriever_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef67ff-8d77-4d90-ba07-1eae886edab8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    ">>>\n",
    ">>> class box:\n",
    "...     def __init__(self):\n",
    "...             print(\"OK\")\n",
    "...\n",
    ">>> obj = box()\n",
    "OK\n",
    ">>> callable(obj)\n",
    "False\n",
    ">>>\n",
    ">>> obj()\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "TypeError: 'box' object is not callable\n",
    ">>>\n",
    ">>> def fx():\n",
    "...     print(\"OK\")\n",
    "...\n",
    ">>> type(fx)\n",
    "<class 'function'>\n",
    ">>>\n",
    ">>> callable(fx)\n",
    "True\n",
    ">>> fx()\n",
    "OK\n",
    ">>> class box:\n",
    "...     def __init__(self):\n",
    "...             pass\n",
    "...     def __call__(self):\n",
    "...             print(\"OK\")\n",
    "...\n",
    ">>> obj = box()\n",
    ">>> callable(obj)\n",
    "True\n",
    ">>>\n",
    ">>> fx.__call__()  # same fx()\n",
    "OK\n",
    ">>>\n",
    ">>> obj()\n",
    "OK\n",
    ">>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "934d79a6-5f77-4a37-bf7b-ba6bf53fe699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Local\\Temp\\ipykernel_29792\\1664598314.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  qa_chain(\"what is langchain?\")\n",
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what is langchain?',\n",
       " 'result': 'LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies the entire process of building, deploying, and managing LLM-based applications, making it easier to create and optimize these applications.\\n\\nLangChain provides an open-source platform that includes various components and integrations to help developers build stateful agents, monitor and evaluate their applications, and deploy them into production.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step-8 QA_Chain ->invoke a query\n",
    "#qa_chain <-- callable object\n",
    "qa_chain(\"what is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aeb0be6-efdf-4fc4-bc75-9de83cef0595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How to write hello world example program in C ?',\n",
       " 'result': 'I don\\'t know how to write a \"Hello World\" example program in C using the context of LangChain, as LangChain seems to be related to large language models and application development, not a programming language like C. However, I can provide a simple \"Hello World\" example program in C:\\n\\n```c\\n#include <stdio.h>\\n\\nint main() {\\n    printf(\"Hello, World!\\\\n\");\\n    return 0;\\n}\\n```\\n\\nTo compile and run this program, you would typically use a C compiler like GCC (GNU Compiler Collection) from the command line:\\n\\n```bash\\ngcc hello.c -o hello\\n./hello\\n```\\n\\nThis will compile the `hello.c` file into an executable named `hello`, and then run the executable, printing \"Hello, World!\" to the console.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain(\"How to write hello world example program in C ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47995cf-215b-4a18-a097-ebdc91ab6c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\karth\\\\AppData\\\\Roaming\\\\Python\\\\Python313\\\\site-packages\\\\langchain\\\\__init__.py'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "838a2d65-3df2-4fc3-bc68-a699ede17b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88c7edfa-d02d-4f96-9cc3-c7361b6865ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\os.py'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0bc0f61-206f-4957-8e6c-d15baf008a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\requests\\\\__init__.py'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e01098-dfa5-4009-8d83-659bc2fae618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca35d97-c8e8-414e-b3c1-452a5d0b53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompting\n",
    "---------\n",
    " |->prompt  - text \n",
    " |->jinja2 - template code ---> {{variable}} \n",
    "\n",
    " |--> instructing an LLM to give the result/output user wants. //How to talk to AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15495d4f-115c-4808-9f9c-6367108ad4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='I likes to read python book')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "PromptTemplate.from_template('I likes to read python book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4601f733-e5bb-401c-8c11-56efe1408855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='I likes to read java book')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PromptTemplate.from_template('I likes to read java book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab826a3-f9fe-49d2-8dc0-9ce0a86ddff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create dynamic value -> template placeholder/variable {variable/placeholder} \n",
    "# PromptTemplate.from_template('user defined prompt') ->object\n",
    "# object.format(userdefined_input_placeholder=Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd6fb4d0-5eb8-4667-b9d9-74da71703ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I likes to read html book'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = PromptTemplate.from_template('I likes to read {myvar} book')\n",
    "obj.format(myvar=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbb72f54-8a34-457c-999c-c48810fc1990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I likes to read story book'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.format(myvar=\"story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14b48347-5ebc-409b-8280-b1c130f9b939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['myvar'], input_types={}, partial_variables={}, template='I likes to read {myvar} book')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5236a721-96ed-4ea8-89cd-5cbb3109906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['author', 'my_year', 'myvar'], input_types={}, partial_variables={}, template='I likes to read {myvar} book written by {author} released on {my_year}')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = PromptTemplate.from_template('I likes to read {myvar} book written by {author} released on {my_year}')\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70e9ed35-8abe-4257-b59d-917bcc7378b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I likes to read birds book written by Mr.ABC released on 2004'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.format(myvar=\"birds\",author=\"Mr.ABC\",my_year=2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5f4e0-51be-4929-a1a1-f52215d66211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
